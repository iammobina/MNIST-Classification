{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "MNIST_BP.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okmzmAs7MwDY",
        "colab_type": "text"
      },
      "source": [
        "#اینجا رو من یه توضیح بدم که چجوری باید استفاده کنید اول کلون کنید این ریپازیتوریو بعد توو قسمت دروایو براتون میاد بعد از قسمت درایو برید در پوشه ی  \n",
        "#tensorflow\n",
        "#بعد از این پوشه پوشه ی examples\n",
        "#روباز کنید و بعدش پوشه ی tutorial\n",
        "# mnist \n",
        "#بعد از آن هم فایل input_data را کپی کنید\n",
        "#در صفحه ی اول درایو قرار بدهید\n",
        "#ایمپورتا درستت کار میکنند"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYNcn-AfKZJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "020db923-aca6-4d83-822a-5d7ac40775e4"
      },
      "source": [
        "!git clone https://github.com/tensorflow/tensorflow.git\n",
        "\n",
        "#اینجا رو من یه توضیح بدم که چجوری باید استفاده کنید اول کلون کنید این ریپازیتوریو بعد توو قسمت دروایو براتون میاد بعد از قسمت درایو برید در پوشه ی  \n",
        "#tensorflow\n",
        "#بعد از این پوشه پوشه ی exampleS\n",
        "#روباز کنید و بعدش پوشه ی tutorial\n",
        "#سپس داده های mnist \n",
        "#براتون دانلود میشه و ایمپورتا درستت کار میکنند"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'tensorflow' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOro3ZPMG46z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "0262cb90-87fd-4464-92f8-ed53b95251c3"
      },
      "source": [
        "import numpy as np\n",
        "import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-37-ebc79193443a>:12: read_data_sets (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as: tensorflow_datasets.load('mnist')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-37-ebc79193443a>:12: read_data_sets (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as: tensorflow_datasets.load('mnist')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/input_data.py:297: _maybe_download (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/input_data.py:297: _maybe_download (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /content/input_data.py:299: _extract_images (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/input_data.py:299: _extract_images (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /content/input_data.py:304: _extract_labels (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/input_data.py:304: _extract_labels (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /content/input_data.py:112: _dense_to_one_hot (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/input_data.py:112: _dense_to_one_hot (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /content/input_data.py:328: _DataSet.__init__ (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/input_data.py:328: _DataSet.__init__ (from input_data) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSN3k-Y1G464",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid_activation(x, deriv=False):\n",
        "    if not deriv:\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    else:\n",
        "        return np.exp(x) / ((np.exp(x) + 1) **2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq2pIAXeG467",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "de77b4d4-ec4d-40ab-fb54-5b7da210d4ee"
      },
      "source": [
        "class Network:\n",
        "    def __init__(self, learning_rate):\n",
        "        self.l1weights = 2 * np.random.random([784, 16]) - 1\n",
        "        self.l1biases = 2 * np.random.random([16]) - 1\n",
        "        self.l2weights = 2 * np.random.random([16, 10]) - 1\n",
        "        self.l2biases = 2 * np.random.random([10]) - 1\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "    def forrwardpassing(self, X):\n",
        "        l1_activation = sigmoid_activation(np.dot(X, self.l1weights) + self.l1biases)\n",
        "        l2_activation = sigmoid_activation(np.dot(l1_activation, self.l2weights) + self.l2biases)\n",
        "        return l2_activation\n",
        "    \n",
        "    def gradient_descent(self, X, Y):\n",
        "\n",
        "        l1_z = np.dot(X, self.l1weights) + self.l1biases\n",
        "        l1_activation = sigmoid_activation(l1_z)\n",
        "        \n",
        "        l2_z = np.dot(l1_activation, self.l2weights) + self.l2biases\n",
        "        l2_activation = sigmoid_activation(l2_z)\n",
        "        \n",
        "\n",
        "        l2_activation_grad = l2_activation - Y\n",
        "        \n",
        "\n",
        "        l2_delta = l2_activation_grad * sigmoid_activation(l2_z, deriv=True)\n",
        "        \n",
        "\n",
        "        l2_weight_grad = np.dot(l1_activation.T, l2_delta) / X.shape[0]\n",
        "        \n",
        "\n",
        "        l2_bias_grad = np.mean(l2_delta, 0).reshape(self.l2biases.shape)\n",
        "        \n",
        "\n",
        "        l1_activation_grad = np.dot(l2_delta, self.l2weights.T)\n",
        "\n",
        "        l1_delta = l1_activation_grad * sigmoid_activation(l1_z, deriv=True)\n",
        "        l1_weight_grad = np.dot(X.T, l1_delta) / X.shape[0]\n",
        "        l1_bias_grad = np.mean(l1_delta, 0).reshape(self.l1biases.shape)\n",
        "        \n",
        "        self.l2weights -= self.learning_rate * l2_weight_grad\n",
        "        self.l2biases -= self.learning_rate * l2_bias_grad\n",
        "        \n",
        "        self.l1weights -= self.learning_rate * l1_weight_grad\n",
        "        self.l1biases -= self.learning_rate * l1_bias_grad\n",
        "        \n",
        "    def accuracy(self, X, Y):\n",
        "        predicted_labels = np.argmax(self.forrwardpassing(X), 1)\n",
        "        true_labels = np.argmax(Y, 1)\n",
        "        return np.mean(np.equal(predicted_labels, true_labels).astype(int))\n",
        "\n",
        "\n",
        "epochs = 20000\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "display_step = 1000\n",
        "\n",
        "net = Network(learning_rate)\n",
        "\n",
        "validation_xs, validation_ys = mnist.train.next_batch(1000)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    xs, ys = mnist.train.next_batch(batch_size)\n",
        "    net.gradient_descent(xs, ys)\n",
        "    if epoch % display_step == 0:\n",
        "        print(\"Number of Epochs\", epoch, \"Accuracy\", net.accuracy(validation_xs, validation_ys))\n",
        "\n",
        "print(\"Number of Epochs\", epoch, \"Accuracy\", net.accuracy(validation_xs, validation_ys))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Epochs 0 Accuracy 0.125\n",
            "Number of Epochs 1000 Accuracy 0.393\n",
            "Number of Epochs 2000 Accuracy 0.508\n",
            "Number of Epochs 3000 Accuracy 0.591\n",
            "Number of Epochs 4000 Accuracy 0.653\n",
            "Number of Epochs 5000 Accuracy 0.698\n",
            "Number of Epochs 6000 Accuracy 0.735\n",
            "Number of Epochs 7000 Accuracy 0.764\n",
            "Number of Epochs 8000 Accuracy 0.786\n",
            "Number of Epochs 9000 Accuracy 0.809\n",
            "Number of Epochs 10000 Accuracy 0.821\n",
            "Number of Epochs 11000 Accuracy 0.833\n",
            "Number of Epochs 12000 Accuracy 0.841\n",
            "Number of Epochs 13000 Accuracy 0.846\n",
            "Number of Epochs 14000 Accuracy 0.85\n",
            "Number of Epochs 15000 Accuracy 0.853\n",
            "Number of Epochs 16000 Accuracy 0.861\n",
            "Number of Epochs 17000 Accuracy 0.868\n",
            "Number of Epochs 18000 Accuracy 0.873\n",
            "Number of Epochs 19000 Accuracy 0.871\n",
            "Number of Epochs 19999 Accuracy 0.874\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}